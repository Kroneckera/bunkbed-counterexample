{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Partitions of Graph Vertices into Connected Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we aim to generate all possible partitions of the vertices in a graph into **connected components**. Each partition represents a different way the vertices could be grouped into distinct connected components, starting from a fully disconnected graph where each vertex is its own component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Set Partition Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates **canonical partitions** of a set of elements (e.g., graph vertices), ensuring that the partitions are consistently ordered for predictability and standardization.\n",
    "\n",
    "Key implementation steps:\n",
    "\n",
    "1. **Partition Generation**:\n",
    "   - The function `generate_canonical_partitions(elements)` generates all possible partitions of the input set using SymPyâ€™s `multiset_partitions`. Each partition is a way to group the elements into distinct subsets.\n",
    "\n",
    "2. **Canonical Representation**:\n",
    "   - Each partition is converted into a **tuple of tuples**, ensuring immutability and making it suitable for use as dictionary keys. The elements in each subset, as well as the subsets themselves, are sorted to maintain a canonical (consistent) order. This ensures that the partitions are presented in a standard form.\n",
    "\n",
    "3. **Mapping Partitions to Indices**:\n",
    "   - The function also constructs a dictionary `partition_to_index` that maps each canonical partition to its respective index in the sorted list of partitions. This mapping allows for efficient referencing of partitions by their index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Partitions:\n",
      "[((1,), (2,), (3,)),\n",
      " ((1,), (2, 3)),\n",
      " ((1, 2), (3,)),\n",
      " ((1, 2, 3),),\n",
      " ((1, 3), (2,))]\n",
      "\n",
      "Partition to Index Mapping:\n",
      "{((1,), (2,), (3,)): 0,\n",
      " ((1,), (2, 3)): 1,\n",
      " ((1, 2), (3,)): 2,\n",
      " ((1, 2, 3),): 3,\n",
      " ((1, 3), (2,)): 4}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sympy.utilities.iterables import multiset_partitions\n",
    "\n",
    "\n",
    "def generate_canonical_partitions(elements):\n",
    "    \"\"\"\n",
    "    Generate canonical partitions for a given set of elements.\n",
    "    A canonical partition is one where both the elements of each subset\n",
    "    and the subsets themselves are sorted in a consistent way. Each partition\n",
    "    is returned as a tuple of tuples.\n",
    "\n",
    "    Parameters:\n",
    "    elements (list): A list of elements to partition.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of canonical partitions, where each partition is a tuple of tuples.\n",
    "    dict: A dictionary mapping each partition (as a tuple of tuples) to its index.\n",
    "    \"\"\"\n",
    "    partitions = list(multiset_partitions(elements))\n",
    "    \n",
    "    # Sort the elements in each subset and the subsets themselves\n",
    "    canonical_partitions = [tuple(sorted(tuple(sorted(subset)) for subset in partition)) for partition in partitions]\n",
    "    canonical_partitions.sort()\n",
    "    \n",
    "    # Create the mapping from partition (tuple of tuples) to its index\n",
    "    partition_to_index = {partition: idx for idx, partition in enumerate(canonical_partitions)}\n",
    "    \n",
    "    return canonical_partitions, partition_to_index\n",
    "\n",
    "# Example usage\n",
    "elements = list(range(1, 4))  # Set of elements {1, 2, 3}\n",
    "canonical_partitions, partition_to_index = generate_canonical_partitions(elements)\n",
    "\n",
    "# Pretty print the results\n",
    "print(\"Canonical Partitions:\")\n",
    "pprint(canonical_partitions, width=60)  # Pretty print with line width control\n",
    "\n",
    "print(\"\\nPartition to Index Mapping:\")\n",
    "pprint(partition_to_index, width=60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Component Partitions and Edge-Based Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we aim to generate all possible **component partitions** of a graph vertices, which are enumerated from `1` to `n_vertices`. \n",
    "\n",
    "Next, we define a **transforms** dictionary that represents how the partition of components changes when an edge is added between two vertices `(a, b)`:\n",
    "- If the vertices `a` and `b` are already in the same connected component, no transformation is needed.\n",
    "- If `a` and `b` belong to different components, the code merges the two components and updates the partition accordingly.\n",
    "\n",
    "The mapping `transforms[(a, b)]` stores the updated partitions for each pair of vertices `(a, b)` after adding the edge. Since adding an edge between `a` and `b` is symmetric, the transformation is also stored for `(b, a)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "# Number of vertices in the graph\n",
    "n_vertices = 10\n",
    "\n",
    "# Generate canonical partitions and the partition-to-index mapping\n",
    "vertices = list(range(1, n_vertices + 1))\n",
    "partitions, partition_map = generate_canonical_partitions(vertices)\n",
    "\n",
    "# Dictionary to store the transformations for each vertex pair\n",
    "transforms = defaultdict(list)\n",
    "\n",
    "# Iterate over all combinations of vertex pairs\n",
    "for a, b in itertools.combinations(vertices, 2):\n",
    "    transform = [0] * len(partitions)\n",
    "    \n",
    "    # Iterate over all partitions\n",
    "    for part_id, part in enumerate(partitions):\n",
    "        # Find the subsets that contain vertices a and b\n",
    "        a_id = next(idx for idx, subset in enumerate(part) if a in subset)\n",
    "        b_id = next(idx for idx, subset in enumerate(part) if b in subset)\n",
    "        \n",
    "        if a_id == b_id:\n",
    "            # No transformation needed if a and b are already in the same subset\n",
    "            transform[part_id] = part_id\n",
    "            continue\n",
    "        \n",
    "        # Create a new partition by merging the subsets that contain a and b\n",
    "        new_part = [part[k] for k in range(len(part)) if k not in [a_id, b_id]]\n",
    "        merged_subset = tuple(sorted(set(part[a_id]).union(set(part[b_id]))))\n",
    "        new_part.append(merged_subset)\n",
    "        new_part.sort()\n",
    "\n",
    "        # Get the index of the new partition\n",
    "        new_part_id = partition_map[tuple(new_part)]\n",
    "        transform[part_id] = new_part_id\n",
    "    \n",
    "    # Store the transformation for both (a, b) and (b, a) since the operation is symmetric\n",
    "    transforms[(a, b)] = transform\n",
    "    transforms[(b, a)] = transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Hyperedge Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "In this setup, we consider a **hyperedge** that connects three vertices $a$, $b$, and $c$ in the WZ model. Vertex $a$ is the selected or central vertex.\n",
    "\n",
    "### Hyperedge Behavior:\n",
    "- **With probability $p_{a|b|c}$**: No edges are added between $a$, $b$, or $c$.\n",
    "- **With probability $p_{a|bc}$**: An edge is added between $b$ and $c$.\n",
    "- **With probability $p_{ab|c}$**: An edge is added between $a$ and $b$.\n",
    "- **With probability $p_{ac|b}$**: An edge is added between $a$ and $c$.\n",
    "- **With probability $p_{abc}$**: The edges between $a$ and $b$ and between $a$ and $c$, are added.\n",
    "\n",
    "### Illustration of the Hyperedge:\n",
    "\n",
    "The illustration below visualizes this structure. Vertex $a$ is placed at the top of an equilateral triangle, while vertices $b$ and $c$ are at the base. The features of the hyperedge are represented as follows:\n",
    "\n",
    "- The **selected vertex** $a$ is marked in **gray** to indicate its central role in the hyperedge.\n",
    "- The **blue edges** represent the connections between the selected vertex $a$ and the non-selected vertices $b$ and $c$.\n",
    "- The **red edge** represents the connection between the non-selected vertices $b$ and $c$.\n",
    "- The interior of the triangle is filled with a **yellow** color to represent the situation where all edges are added with probability $p_{abc}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<img src=\"hyperedge.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Poly\n",
    "import numpy as np\n",
    "\n",
    "# Define symbolic variables for the probabilities\n",
    "hyperedge_probs = {\n",
    "    'a|b|c': symbols('p_{a|b|c}'), \n",
    "    'a|bc': symbols('p_{a|bc}'),\n",
    "    'ac|b': symbols('p_{ac|b}'),\n",
    "    'ab|c': symbols('p_{ab|c}'),\n",
    "    'abc': symbols('p_{abc}'),\n",
    "}\n",
    "gens = list(hyperedge_probs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Hyperedge Additions to Partition Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_hyperedge` function models how adding a $3$-edge in the WZ model between three vertices `(a, b, c)` affects the probability distribution over all possible partitions of the graph's vertices. The function applies hyperedge addition transformations to the partition probabilities for the triangle of vertices and updates the connected components based on these additions.\n",
    "\n",
    "Key steps in the implementation:\n",
    "\n",
    "1. **Input Parameters**:\n",
    "   - `probs`: A list representing the current probability distribution over partitions.\n",
    "   - `vertices`: A tuple containing the three vertices `(a, b, c)` involved in the transformation.\n",
    "   - `edge_probs`: A dictionary of formal variables representing the probabilities of adding a $3$-edge of a particular type in WZ model. The keys correspond to the partitions of the set $\\{a, b, c\\}$.\n",
    "   - `transforms`: A dictionary that defines how the partitions are transformed when specific edges are added.\n",
    "\n",
    "2. **Updating Partition Probabilities**:\n",
    "   - The function initializes a new list `new_probs`, which starts as the current `probs` scaled by the probability of no edges being added (`'a|b|c'`).\n",
    "   - It then loops over all partition indices and applies one of the transformations for each edge addition case:\n",
    "     - With probability `'a|bc'` it adds the edge between `b` and `c` and updates the corresponding partition.\n",
    "     - With probability `'b|ac'` it adds the edge between `a` and `c` and updates the partition.\n",
    "     - With probability `'c|ab'` it adds the edge between `a` and `b` and updates the partition.\n",
    "     - Finally, with probability `'abc'` it adds both edges `a-b` and `a-c` and updates the partition accordingly.\n",
    "\n",
    "The function returns the new probability distribution `new_probs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hyperedge(probs, vertices, edge_probs, transforms):\n",
    "    \"\"\"\n",
    "    Applies edge addition transformations to the partition probabilities for a triangle of vertices (a, b, c).\n",
    "\n",
    "    Parameters:\n",
    "    probs (list): The current probability distribution over partitions.\n",
    "    vertices (tuple): The three vertices (a, b, c) involved in the transformation.\n",
    "    edge_probs (dict): A dictionary of probabilities for different edge additions. Keys:\n",
    "        - 'a|b|c': probability of no edges being added.\n",
    "        - 'a|bc': probability of adding edge between b and c.\n",
    "        - 'ac|b': probability of adding edge between a and c.\n",
    "        - 'ab|c': probability of adding edge between a and b.\n",
    "        - 'abc': probability of adding edges a-b and a-c.\n",
    "    transforms (dict): The transformation dictionary that maps every edge to how partitions change when the edge is added.\n",
    "\n",
    "    Returns:\n",
    "    new_probs (list): Updated probability distribution over partitions.\n",
    "    \"\"\"\n",
    "    a, b, c = vertices\n",
    "    \n",
    "    # Create a new list to store the updated probabilities\n",
    "    new_probs = probs * edge_probs['a|b|c']  # Initialize with scaled probs for 'a|b|c' (no edges added)\n",
    "    \n",
    "    # Loop over each partition index\n",
    "    for k in range(len(probs)):\n",
    "        # a|bc -- adding edge between b and c\n",
    "        new_probs[transforms[(b, c)][k]] += probs[k] * edge_probs['a|bc']\n",
    "        \n",
    "        # ac|b -- adding edge between a and c\n",
    "        new_probs[transforms[(a, c)][k]] += probs[k] * edge_probs['ac|b']\n",
    "        \n",
    "        # ab|c -- adding edge between a and b\n",
    "        new_probs[transforms[(a, b)][k]] += probs[k] * edge_probs['ab|c']\n",
    "        \n",
    "        # abc -- adding both edges a-b and a-c\n",
    "        idx = transforms[(a, b)][k]\n",
    "        idx = transforms[(a, c)][idx]\n",
    "        new_probs[idx] += probs[k] * edge_probs['abc']\n",
    "    \n",
    "    return new_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph with 10 Vertices and Hyperedges\n",
    "\n",
    "We now consider Hollom's $3$-regular hypergraph with **10 vertices**, labeled from $u_1$ to $u_{10}$. In this graph, we add **6 i.i.d. hyperedges**, as illustrated in the diagram below.\n",
    "\n",
    "<img src=\"graph.png\" width=350>\n",
    "\n",
    "We run a WZ percolation on this hypergraph. Specifically, the hyperedges act between the following sets of vertices (the first vertex of each hyperedge is the selected one):\n",
    "1. $(u_2, u_1, u_3)$\n",
    "2. $(u_2, u_4, u_5)$\n",
    "3. $(u_9, u_3, u_6)$\n",
    "4. $(u_7, u_4, u_8)$\n",
    "5. $(u_7, u_5, u_6)$\n",
    "6. $(u_9, u_8, u_{10})$\n",
    "\n",
    "In the graph, the **transversal vertices** ($u_2$, $u_7$, and $u_9$) are marked in **gray**, and the edges between these vertices and other vertices are represented in **blue**. The edge between two non-selected vertices is shown in **red**. \n",
    "\n",
    "We aim to find the probability distribution on the connected components of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize probs as a zeros array of polynomials with one non-zero initial element\n",
    "probs = np.zeros(len(partitions), dtype=object)\n",
    "probs[0] = Poly(1, gens)  # Start with the first partition having probability 1\n",
    "\n",
    "# Apply add_hyperedge (previously add_triangle) for specific vertex triples\n",
    "probs = add_hyperedge(probs, [2, 1, 3], hyperedge_probs, transforms)\n",
    "probs = add_hyperedge(probs, [2, 4, 5], hyperedge_probs, transforms)\n",
    "probs = add_hyperedge(probs, [7, 5, 6], hyperedge_probs, transforms)\n",
    "probs = add_hyperedge(probs, [7, 4, 8], hyperedge_probs, transforms)\n",
    "probs = add_hyperedge(probs, [9, 3, 6], hyperedge_probs, transforms)\n",
    "probs = add_hyperedge(probs, [9, 8, 10], hyperedge_probs, transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricting to Key Vertices for the Bunkbed Problem\n",
    "\n",
    "In the context of the **bunkbed conjecture**, our objective does not require knowledge of the probability distribution over all possible partitions of the entire graph's vertices. Instead, the problem can be simplified by focusing only on a subset of **key vertices** -- specifically, the source vertex $u_1$, the target vertex $u_{10}$, and the transversal vertices $u_2$, $u_7$, and $u_9$. \n",
    "\n",
    "Rather than working with the full partitions of the graph, which include all 10 vertices, we are primarily interested in the probability distribution over the connected components of this smaller subset of **5 key vertices**. \n",
    "\n",
    "#### Approach:\n",
    "1. **Mapping Full Partitions to Key Vertices**:\n",
    "   - To achieve this reduction, we first define a **restriction mapping** that projects each full partition of the 10 vertices onto a partition of the key vertices. This mapping essentially discards the irrelevant vertices and focuses solely on how the source, target, and transversal vertices are connected to one another in the partition.\n",
    "\n",
    "2. **Computing the Probability Distribution**:\n",
    "   - Once the restriction mapping is defined, we can apply it to the probabilities associated with the full partitions. By doing so, we transform the probability distribution over the full set of partitions into a probability distribution over the partitions of the key vertices which we call **restricted partitions**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source, target, and transversal vertices\n",
    "source_vertex = 1\n",
    "target_vertex = 10\n",
    "transversal_vertices = [2, 7, 9]\n",
    "\n",
    "# Define the subset of vertices we are interested in (source, target, and transversals)\n",
    "restricted_vertices = [source_vertex] + transversal_vertices + [target_vertex]\n",
    "\n",
    "# Generate canonical partitions and the partition-to-index mapping for the restricted vertices\n",
    "restricted_partitions, restricted_partition_map = generate_canonical_partitions(restricted_vertices)\n",
    "\n",
    "# Initialize an array to store the mapping from the full partition space to the restricted partition space\n",
    "projection_map = np.zeros(len(partitions), dtype=int)\n",
    "\n",
    "# Map each full partition to the corresponding restricted partition\n",
    "for part_id, full_part in enumerate(partitions):\n",
    "    # Restrict the full partition to the set of restricted vertices\n",
    "    restricted_part = [sorted(set(block).intersection(restricted_vertices)) for block in full_part]\n",
    "    restricted_part = [block for block in restricted_part if block]  # Remove empty blocks\n",
    "    restricted_part.sort()\n",
    "\n",
    "    # Get the corresponding index for the restricted partition\n",
    "    restricted_part_id = restricted_partition_map[tuple(map(tuple, restricted_part))]\n",
    "    projection_map[part_id] = restricted_part_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array for the probability distribution over restricted partitions\n",
    "restricted_probs = np.zeros(len(restricted_partitions), dtype=object)\n",
    "\n",
    "for full_part_id, full_part in enumerate(partitions):\n",
    "    restricted_part_id = projection_map[full_part_id]    \n",
    "    restricted_probs[restricted_part_id] += probs[full_part_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective in the Bunkbed Conjecture: Computing the Difference of Probabilities\n",
    "\n",
    "In this part of the code, we compute the **difference of two probabilities** that are central to the **bunkbed conjecture for WZ-percolation**. The conjecture involves analyzing the bunkbed graph that contains two independent copies of a hypergraph with transversal vertices connected to their copies via posts.\n",
    "\n",
    "## Setup:\n",
    "1. **Two Independent Copies of the Graph**:\n",
    "   - We create two independent copies of the original graph:\n",
    "     - The vertices of the **first copy** are labeled as $(u, 1)$.\n",
    "     - The vertices of the **second copy** are labeled as $(u, 2)$.\n",
    "   - These copies are identical except that corresponding **transversal vertices** in both copies are connected with probability 1. In this example, the transversal vertices are $u_2$, $u_7$, and $u_9$.\n",
    "\n",
    "2. **Two Key Probabilities**:\n",
    "   We are interested in computing the following two probabilities:\n",
    "   - The probability that the source vertex in the first copy $(u_1, 1)$ is connected to the target vertex in the same copy $(u_{10}, 1)$.\n",
    "   - The probability that the source vertex in the first copy $(u_1, 1)$ is connected to the target vertex in the second copy $(u_{10}, 2)$.\n",
    "\n",
    "3. **Objective**:\n",
    "   The **difference** between these two probabilities is the objective of the bunkbed conjecture. This code computes this difference by iterating over all possible partitions of the key vertices and evaluating how the source and target vertices are connected in the two graph copies.\n",
    "\n",
    "## How the Code Works:\n",
    "- **Block Combination**:\n",
    "  - For each partition of the graph, represented by $q_1$ and $q_2$ for the two copies, we label the vertices in each copy as $(u, 1)$ and $(u, 2)$.\n",
    "  - The code combines the partitions from both copies into **blocks** and iterates over each of the **transversal vertices** $(u_2, u_7, u_9)$. The blocks containing these transversal vertices are **merged** to ensure that corresponding vertices in the two copies are connected.\n",
    "\n",
    "- **Connectivity Check**:\n",
    "  - After processing the transversal vertices, the code checks:\n",
    "    - Whether the source vertex $(u_1, 1)$ and target vertex $(u_{10}, 1)$ are in the **same connected component** in the first copy.\n",
    "    - Whether the source vertex $(u_1, 1)$ and target vertex $(u_{10}, 2)$ are in the **same connected component** across both copies.\n",
    "\n",
    "- **Updating the Objective**:\n",
    "  - If the source and target are connected in the **first copy** ($(u_1, 1)$ and $(u_{10}, 1)$ are in the same block), the product of their probabilities from the partition probability distribution is **added** to the objective.\n",
    "  - If the source and target are connected **across both copies** ($(u_1, 1)$ and $(u_{10}, 2)$ are in the same block), the product of their probabilities is **subtracted** from the objective.\n",
    "\n",
    "This iterative process over all possible partitions and combinations of the two graph copies yields the final objective value in `bunkbed_obj`. The conjecture claims that `bunkbed_obj` is nonnegative for any hypergraph and probabilities that can be emulated in edge percolation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunkbed_obj = Poly(0, gens) # Initialize the polynomial for the final objective\n",
    "\n",
    "# Iterate over all combinations of partitions for the two independent graph copies\n",
    "for part_1_id, part_1 in enumerate(restricted_partitions):\n",
    "    for part_2_id, part_2 in enumerate(restricted_partitions):\n",
    "        # Create blocks by combining the partitions from the two copies\n",
    "        # First copy vertices are labeled as (u, 1) and second copy vertices as (u, 2)\n",
    "        combined_blocks = [list(map(lambda v: (v, 1), block)) for block in part_1] + \\\n",
    "                          [list(map(lambda v: (v, 2), block)) for block in part_2]\n",
    "\n",
    "        # Process the transversal vertices, ensuring they are connected between the two copies\n",
    "        for vertex in transversal_vertices:\n",
    "            block_1_idx = next(idx for idx, block in enumerate(combined_blocks) if (vertex, 1) in block)\n",
    "            block_2_idx = next(idx for idx, block in enumerate(combined_blocks) if (vertex, 2) in block)\n",
    "\n",
    "            # Merge the blocks containing the transversal vertex in both copies\n",
    "            new_combined_blocks = [\n",
    "                combined_blocks[i] for i in range(len(combined_blocks))\n",
    "                if i not in [block_1_idx, block_2_idx]\n",
    "            ]\n",
    "            merged_block = sorted(set(combined_blocks[block_1_idx]).union(combined_blocks[block_2_idx]))\n",
    "            new_combined_blocks.append(merged_block)\n",
    "            combined_blocks = new_combined_blocks\n",
    "\n",
    "        # Check if source and target are connected in the first copy\n",
    "        if any((source_vertex, 1) in block and (target_vertex, 1) in block for block in combined_blocks):\n",
    "            bunkbed_obj += restricted_probs[part_1_id] * restricted_probs[part_2_id]\n",
    "        \n",
    "        # Check if source and target are connected across both copies\n",
    "        if any((source_vertex, 1) in block and (target_vertex, 2) in block for block in combined_blocks):\n",
    "            bunkbed_obj -= restricted_probs[part_1_id] * restricted_probs[part_2_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Polynomial: Coefficient Extraction and Factorization\n",
    "\n",
    "In this part of the analysis, we turn our attention to the polynomial that arises from the bunkbed conjecture and its associated probability terms. Our focus is on isolating and understanding the structure of the terms involving powers of $p_{a|bc}^k$. Specifically, we will extract the coefficients of $p_{a|bc}^k$ as polynomials in $p_{abc}$ and the remaining variables, and subsequently factorize these expressions to reveal any underlying structure.\n",
    "\n",
    "Given the expanded form of the polynomial\n",
    "\n",
    "$$\n",
    "BB(p_{abc}, p_{a|bc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}),\n",
    "$$\n",
    "\n",
    "we isolate the terms containing powers of $p_{a|bc}^k$. For a fixed $k$, the coefficient of $p_{a|bc}^k$ is extracted and written as a polynomial in the remaining variables $p_{abc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}$. The resulting expression is denoted as:\n",
    "\n",
    "$$\n",
    "\\text{Coeff}(p_{a|bc}^k) = C_k(p_{abc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}),\n",
    "$$\n",
    "\n",
    "where $C_k$ represents the polynomial that forms the coefficient of $p_{a|bc}^k$. After isolating $C_k$, we proceed to factorize this polynomial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{0}: - \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right)^{6}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{1}: - 2 \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right)^{5} \\left(p_{abc} - 2 p_{ab|c} - 2 p_{ac|b} - 2 p_{a|b|c}\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{2}: \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right)^{4} \\left(8 p_{abc}^{2} + 27 p_{abc} p_{ab|c} + 23 p_{abc} p_{ac|b} + 28 p_{abc} p_{a|b|c} + 3 p_{ab|c}^{2} + p_{ab|c} p_{ac|b} + 4 p_{ab|c} p_{a|b|c} + p_{ac|b}^{2} + 4 p_{ac|b} p_{a|b|c} + 2 p_{a|b|c}^{2}\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{3}: 2 \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right)^{3} \\left(16 p_{abc}^{3} + 37 p_{abc}^{2} p_{ab|c} + 33 p_{abc}^{2} p_{ac|b} + 49 p_{abc}^{2} p_{a|b|c} + 12 p_{abc} p_{ab|c}^{2} + 14 p_{abc} p_{ab|c} p_{ac|b} + 30 p_{abc} p_{ab|c} p_{a|b|c} + 12 p_{abc} p_{ac|b}^{2} + 32 p_{abc} p_{ac|b} p_{a|b|c} + 18 p_{abc} p_{a|b|c}^{2} + 3 p_{ab|c}^{3} + 7 p_{ab|c}^{2} p_{ac|b} + 11 p_{ab|c}^{2} p_{a|b|c} + 8 p_{ab|c} p_{ac|b}^{2} + 20 p_{ab|c} p_{ac|b} p_{a|b|c} + 12 p_{ab|c} p_{a|b|c}^{2} + 4 p_{ac|b}^{3} + 12 p_{ac|b}^{2} p_{a|b|c} + 12 p_{ac|b} p_{a|b|c}^{2} + 4 p_{a|b|c}^{3}\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{4}: \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right)^{2} \\left(45 p_{abc}^{4} + 123 p_{abc}^{3} p_{ab|c} + 119 p_{abc}^{3} p_{ac|b} + 225 p_{abc}^{3} p_{a|b|c} + 103 p_{abc}^{2} p_{ab|c}^{2} + 150 p_{abc}^{2} p_{ab|c} p_{ac|b} + 324 p_{abc}^{2} p_{ab|c} p_{a|b|c} + 115 p_{abc}^{2} p_{ac|b}^{2} + 338 p_{abc}^{2} p_{ac|b} p_{a|b|c} + 219 p_{abc}^{2} p_{a|b|c}^{2} + 57 p_{abc} p_{ab|c}^{3} + 115 p_{abc} p_{ab|c}^{2} p_{ac|b} + 219 p_{abc} p_{ab|c}^{2} p_{a|b|c} + 124 p_{abc} p_{ab|c} p_{ac|b}^{2} + 380 p_{abc} p_{ab|c} p_{ac|b} p_{a|b|c} + 260 p_{abc} p_{ab|c} p_{a|b|c}^{2} + 66 p_{abc} p_{ac|b}^{3} + 230 p_{abc} p_{ac|b}^{2} p_{a|b|c} + 262 p_{abc} p_{ac|b} p_{a|b|c}^{2} + 96 p_{abc} p_{a|b|c}^{3} + 11 p_{ab|c}^{4} + 22 p_{ab|c}^{3} p_{ac|b} + 46 p_{ab|c}^{3} p_{a|b|c} + 21 p_{ab|c}^{2} p_{ac|b}^{2} + 90 p_{ab|c}^{2} p_{ac|b} p_{a|b|c} + 71 p_{ab|c}^{2} p_{a|b|c}^{2} + 24 p_{ab|c} p_{ac|b}^{3} + 92 p_{ab|c} p_{ac|b}^{2} p_{a|b|c} + 118 p_{ab|c} p_{ac|b} p_{a|b|c}^{2} + 48 p_{ab|c} p_{a|b|c}^{3} + 12 p_{ac|b}^{4} + 48 p_{ac|b}^{3} p_{a|b|c} + 72 p_{ac|b}^{2} p_{a|b|c}^{2} + 48 p_{ac|b} p_{a|b|c}^{3} + 12 p_{a|b|c}^{4}\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Coefficient of } p_{a|bc}^{5}: \\left(p_{abc} p_{a|b|c} - p_{ab|c} p_{ac|b}\\right) \\left(34 p_{abc}^{5} + 130 p_{abc}^{4} p_{ab|c} + 134 p_{abc}^{4} p_{ac|b} + 320 p_{abc}^{4} p_{a|b|c} + 186 p_{abc}^{3} p_{ab|c}^{2} + 258 p_{abc}^{3} p_{ab|c} p_{ac|b} + 733 p_{abc}^{3} p_{ab|c} p_{a|b|c} + 208 p_{abc}^{3} p_{ac|b}^{2} + 761 p_{abc}^{3} p_{ac|b} p_{a|b|c} + 607 p_{abc}^{3} p_{a|b|c}^{2} + 142 p_{abc}^{2} p_{ab|c}^{3} + 185 p_{abc}^{2} p_{ab|c}^{2} p_{ac|b} + 672 p_{abc}^{2} p_{ab|c}^{2} p_{a|b|c} + 191 p_{abc}^{2} p_{ab|c} p_{ac|b}^{2} + 1037 p_{abc}^{2} p_{ab|c} p_{ac|b} p_{a|b|c} + 966 p_{abc}^{2} p_{ab|c} p_{a|b|c}^{2} + 156 p_{abc}^{2} p_{ac|b}^{3} + 708 p_{abc}^{2} p_{ac|b}^{2} p_{a|b|c} + 984 p_{abc}^{2} p_{ac|b} p_{a|b|c}^{2} + 420 p_{abc}^{2} p_{a|b|c}^{3} + 48 p_{abc} p_{ab|c}^{4} + 14 p_{abc} p_{ab|c}^{3} p_{ac|b} + 247 p_{abc} p_{ab|c}^{3} p_{a|b|c} - 70 p_{abc} p_{ab|c}^{2} p_{ac|b}^{2} + 297 p_{abc} p_{ab|c}^{2} p_{ac|b} p_{a|b|c} + 457 p_{abc} p_{ab|c}^{2} p_{a|b|c}^{2} + 294 p_{abc} p_{ab|c} p_{ac|b}^{2} p_{a|b|c} + 664 p_{abc} p_{ab|c} p_{ac|b} p_{a|b|c}^{2} + 360 p_{abc} p_{ab|c} p_{a|b|c}^{3} + 50 p_{abc} p_{ac|b}^{4} + 258 p_{abc} p_{ac|b}^{3} p_{a|b|c} + 466 p_{abc} p_{ac|b}^{2} p_{a|b|c}^{2} + 360 p_{abc} p_{ac|b} p_{a|b|c}^{3} + 102 p_{abc} p_{a|b|c}^{4} + 6 p_{ab|c}^{5} - 13 p_{ab|c}^{4} p_{ac|b} + 30 p_{ab|c}^{4} p_{a|b|c} - 51 p_{ab|c}^{3} p_{ac|b}^{2} - 19 p_{ab|c}^{3} p_{ac|b} p_{a|b|c} + 60 p_{ab|c}^{3} p_{a|b|c}^{2} - 58 p_{ab|c}^{2} p_{ac|b}^{3} - 80 p_{ab|c}^{2} p_{ac|b}^{2} p_{a|b|c} + 36 p_{ab|c}^{2} p_{ac|b} p_{a|b|c}^{2} + 60 p_{ab|c}^{2} p_{a|b|c}^{3} - 20 p_{ab|c} p_{ac|b}^{4} - 26 p_{ab|c} p_{ac|b}^{3} p_{a|b|c} + 36 p_{ab|c} p_{ac|b}^{2} p_{a|b|c}^{2} + 72 p_{ab|c} p_{ac|b} p_{a|b|c}^{3} + 30 p_{ab|c} p_{a|b|c}^{4} + 6 p_{ac|b}^{5} + 30 p_{ac|b}^{4} p_{a|b|c} + 60 p_{ac|b}^{3} p_{a|b|c}^{2} + 60 p_{ac|b}^{2} p_{a|b|c}^{3} + 30 p_{ac|b} p_{a|b|c}^{4} + 6 p_{a|b|c}^{5}\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sympy import collect, factor, symbols, latex\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# Collect terms in the polynomial expression based on powers of p_{a|bc}\n",
    "collected_bunkbed_on_p2 = collect(bunkbed_obj.as_expr(), hyperedge_probs['a|bc'])\n",
    "\n",
    "# Iterate over the range of powers for p_{a|bc}, from 0 to 6\n",
    "for k in range(6):\n",
    "    # Extract the coefficient of the term (p_{a|bc})^k from the collected expression\n",
    "    coeff_k = collected_bunkbed_on_p2.coeff(hyperedge_probs['a|bc'], k)\n",
    "    \n",
    "    # Factorize the extracted coefficient for simplicity and pattern recognition\n",
    "    factored_coeff_k = factor(coeff_k)\n",
    "    \n",
    "    # Prepare a LaTeX string to display the factored coefficient nicely\n",
    "    latex_expr = f\"\\\\text{{Coefficient of }} p_{{a|bc}}^{{{k}}}: \" + latex(factored_coeff_k)\n",
    "    \n",
    "    # Display the LaTeX representation of the factored coefficient in the notebook\n",
    "    display(Math(latex_expr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisibility and Estimation of Coefficients\n",
    "\n",
    "We observe that the coefficient of $p_{a|bc}^k$, denoted as $\\text{Coeff}(p_{a|bc}^k)$, is divisible by the factor $(p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b})^{6 - k}$ for $0 \\leq k \\leq 6$. Specifically, the coefficient of $p_{a|bc}^0$ is given by:\n",
    "\n",
    "$$\n",
    "\\text{Coeff}(p_{a|bc}^0) = - \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^6.\n",
    "$$\n",
    "\n",
    "For $1 \\leq k \\leq 6$, we can estimate the coefficient $\\text{Coeff}(p_{a|bc}^k)$ from above as:\n",
    "\n",
    "$$\n",
    "\\text{Coeff}(p_{a|bc}^k) \\leq \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^{6 - k} \\cdot s_k,\n",
    "$$\n",
    "\n",
    "where $s_k$ is some constant.\n",
    "\n",
    "For $k \\geq 7$, the coefficient $\\text{Coeff}(p_{a|bc}^k)$ is estimated from above as a constant $s_k$.\n",
    "\n",
    "Thus, we can estimate the entire polynomial $BB(p_{abc}, p_{a|bc}, p_{ab|c}, p_{ac|b}, p_{a|b|c})$ as:\n",
    "\n",
    "$$\n",
    "BB(p_{abc}, p_{a|bc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}) \\leq - \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^6 + \\sum_{k=1}^6 s_k \\cdot p_{a|bc}^k \\cdot \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^{6 - k} + \\sum_{k=7}^{12} s_k \\cdot p_{a|bc}^k.\n",
    "$$\n",
    "\n",
    "Given that $p_{a|bc} \\leq 1$, we can bound last terms of this polynomial from above:\n",
    "$$\n",
    "\\sum_{k=7}^{12} s_k \\cdot p_{a|bc}^k \\leq p_{a|bc}^6\\sum_{k = 7}^{12}|s_k|.\n",
    "$$\n",
    "\n",
    "Denoting $c_k = s_k$ for $1 \\le k \\le 5$ and $c_6 = s_6 + \\sum_{k = 7}^{12}|s_k|$, we finally get an estimate\n",
    "$$\n",
    "BB(p_{abc}, p_{a|bc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}) \\leq - \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^6 + \\sum_{k=1}^6 c_k \\cdot p_{a|bc}^k \\cdot \\left( p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} \\right)^{6 - k}.\n",
    "$$\n",
    "\n",
    "Denoting \n",
    "\n",
    "$$\n",
    "t = \\frac{p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b}}{p_{a|bc}},\n",
    "$$\n",
    "\n",
    "we can further estimate it as:\n",
    "\n",
    "$$\n",
    "BB(p_{abc}, p_{a|bc}, p_{ab|c}, p_{ac|b}, p_{a|b|c}) \\leq p_{a|bc}^6 \\cdot \\left( - t^6 + \\sum_{k = 0}^5 c_{6-k} t^k \\right),\n",
    "$$\n",
    "\n",
    "where $c_k$ are absolute constants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficient Condition For Counterexample\n",
    "\n",
    "We observe that the polynomial\n",
    "\n",
    "$$\n",
    "-t^6 + \\sum_{k=0}^5 c_{6-k} t^k\n",
    "$$\n",
    "\n",
    "is negative for $t > |c_1| + |c_2| + \\cdots + |c_6|$. This implies that for sufficiently large $t$, the expression will always be negative. Thus, it is sufficient to show that for any constant $C$, we can construct a gadget graph such that:\n",
    "\n",
    "$$\n",
    "p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b} > C \\cdot p_{a|bc}.\n",
    "$$\n",
    "\n",
    "This construction will guarantee that $t = \\frac{p_{abc} \\cdot p_{a|b|c} - p_{ab|c} \\cdot p_{ac|b}}{p_{a|bc}}$ exceeds the threshold $|c_1| + |c_2| + \\cdots + |c_6|$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the Gadget Graph Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a graph $G_n$ with a central vertex $a$ and $n$ peripheral vertices $u_1, u_2, \\dots, u_n$. Vertex $a$ is connected to each peripheral vertex $u_i$ by an edge that is open with probability $1 - p$, and each peripheral vertex $u_i$ is connected to its neighbor $u_{i+1}$ by an edge that is open with probability $p$.\n",
    "\n",
    "We will use this graph to model the hyperedge in the bunkbed conjecture, where vertex $b = u_1$ and vertex $c = u_n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<img src=\"gadget.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorem\n",
    "\n",
    "In a graph $G_n$:\n",
    "\n",
    "\\begin{align*}\n",
    "p_{ab} &= p_{ac} = P(a \\leftrightarrow u_1) = \\frac{1 - p^{2n}}{1 + p} \\\\\n",
    "p_{abc} &= P(a \\leftrightarrow u_1 \\land a \\leftrightarrow u_n) = \\frac{1 - p^{2n} + n(1 - p^2)p^{2n-1}}{(1 + p)^2} \\\\\n",
    "p_{a|bc} &= p^{2n - 1}\n",
    "\\end{align*}\n",
    "\n",
    "and therefore,\n",
    "\n",
    "\\begin{align*}\n",
    "p_{abc}p_{a|b|c} - p_{ab|c}p_{ac|b} &> \\left(n\\frac{1 - p}{1 + p} - 1\\right)p_{a|bc}.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smallest counterexample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the derived formulas for $p_{abc}$, $p_{ab}$, $p_{ac}$, and $p_{a|bc}$ to get better estimates on the number of vertices in the optimal graph. By substituting these probability expressions into the overall polynomial model for the bunkbed conjecture, we aim to find the number of peripheral vertices $n$ that provides a counterexample to the bunkbed conjecture. It turns out that $n = 5$ suffices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 2241 p^{108} + 19166 p^{107} - 84725 p^{106} + 262714 p^{105} - 649573 p^{104} + 1372150 p^{103} - 2581261 p^{102} + 4442028 p^{101} - 7122167 p^{100} + 10778486 p^{99} - 15538216 p^{98} + 21474692 p^{97} - 28590303 p^{96} + 36822496 p^{95} - 46076471 p^{94} + 56280040 p^{93} - 67454251 p^{92} + 79791382 p^{91} - 93727626 p^{90} + 109993960 p^{89} - 129631701 p^{88} + 153961428 p^{87} - 184490415 p^{86} + 222749224 p^{85} - 270064340 p^{84} + 327287334 p^{83} - 394512058 p^{82} + 470822126 p^{81} - 554117065 p^{80} + 641064310 p^{79} - 727210644 p^{78} + 807262504 p^{77} - 875523190 p^{76} + 926456304 p^{75} - 955319287 p^{74} + 958780088 p^{73} - 935408030 p^{72} + 885943726 p^{71} - 813303442 p^{70} + 722320268 p^{69} - 619248441 p^{68} + 511079838 p^{67} - 404751334 p^{66} + 306350834 p^{65} - 220461924 p^{64} + 149794452 p^{63} - 95165863 p^{62} + 55762370 p^{61} - 29553471 p^{60} + 13772056 p^{59} - 5409516 p^{58} + 1676380 p^{57} - 366060 p^{56} + 44444 p^{55} - 1184 p^{54}$"
      ],
      "text/plain": [
       "-2241*p**108 + 19166*p**107 - 84725*p**106 + 262714*p**105 - 649573*p**104 + 1372150*p**103 - 2581261*p**102 + 4442028*p**101 - 7122167*p**100 + 10778486*p**99 - 15538216*p**98 + 21474692*p**97 - 28590303*p**96 + 36822496*p**95 - 46076471*p**94 + 56280040*p**93 - 67454251*p**92 + 79791382*p**91 - 93727626*p**90 + 109993960*p**89 - 129631701*p**88 + 153961428*p**87 - 184490415*p**86 + 222749224*p**85 - 270064340*p**84 + 327287334*p**83 - 394512058*p**82 + 470822126*p**81 - 554117065*p**80 + 641064310*p**79 - 727210644*p**78 + 807262504*p**77 - 875523190*p**76 + 926456304*p**75 - 955319287*p**74 + 958780088*p**73 - 935408030*p**72 + 885943726*p**71 - 813303442*p**70 + 722320268*p**69 - 619248441*p**68 + 511079838*p**67 - 404751334*p**66 + 306350834*p**65 - 220461924*p**64 + 149794452*p**63 - 95165863*p**62 + 55762370*p**61 - 29553471*p**60 + 13772056*p**59 - 5409516*p**58 + 1676380*p**57 - 366060*p**56 + 44444*p**55 - 1184*p**54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import expand  # We will use expand to simplify the result\n",
    "\n",
    "\n",
    "n = 5  # Number of peripheral vertices in the graph\n",
    "p = symbols('p')  # Symbolic representation of the edge probability p\n",
    "\n",
    "# Define the probability expressions for the various events in terms of p and n\n",
    "probs = {\n",
    "    # p_abc: The probability that a is connected to both b (u_1) and c (u_n) via open edges\n",
    "    'abc': Poly((1 - p**(2*n) + n * (1 - p)*(1 + p) * p**(2*n - 1)), [p]) // (1 + p)**2,\n",
    "    \n",
    "    # p_ab and p_ac: The probabilities that a is connected to b or c respectively\n",
    "    'ab': Poly(1 - p**(2*n), [p]) // (1 + p),\n",
    "    'ac': Poly(1 - p**(2*n), [p]) // (1 + p),\n",
    "    \n",
    "    # p_a|bc: The probability that a is connected to b but not directly to c\n",
    "    'a|bc': Poly(p**(2*n - 1), [p])\n",
    "}\n",
    "\n",
    "# Substitute these probability expressions into the bunkbed conjecture's objective function (bunkbed_obj)\n",
    "substituted_bunkbed_obj = bunkbed_obj.subs({\n",
    "    hyperedge_probs['abc']: probs['abc'].as_expr(),  # Substituting p_abc\n",
    "    hyperedge_probs['ab|c']: (probs['ab'] - probs['abc']).as_expr(),  # p_ab|c = p_ab - p_abc\n",
    "    hyperedge_probs['ac|b']: (probs['ac'] - probs['abc']).as_expr(),  # p_ac|b = p_ac - p_abc\n",
    "    hyperedge_probs['a|bc']: (probs['a|bc']).as_expr(),  # Substituting p_a|bc\n",
    "    # p_a|b|c: The probability that a is connected neither to b nor c\n",
    "    hyperedge_probs['a|b|c']: (1 - probs['ab'] - probs['ac'] - probs['a|bc'] + probs['abc']).as_expr()\n",
    "})\n",
    "\n",
    "# Expand and simplify the resulting polynomial expression\n",
    "expand(substituted_bunkbed_obj.as_expr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n = 5$, the term $-1184 p^{54}$ dominates all other terms as $p \\to 0$. This means that for sufficiently small values of $p$, the polynomial becomes negative. Consequently, if $p$ is close enough to 0, the polynomial expression is negative, which implies that a counterexample to the bunkbed conjecture can be found with $10 + 6(n-2) = 28$ vertices. Moreover, the resulting graph is also planar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate this polynomial at specific points to better understand its behavior. One such point is $p = 0.0348$, which is close to the minimum of the polynomial. The value of the polynomial at this point is approximately:\n",
    "\n",
    "$$\n",
    "-3 \\times 10^{-78}\n",
    "$$\n",
    "\n",
    "This extremely small value highlights how the polynomial remains negative at $p = 0.0348$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.04183545634913e-78\n"
     ]
    }
   ],
   "source": [
    "p_value = 0.0348\n",
    "result_at_p = substituted_bunkbed_obj.evalf(subs={p: p_value})\n",
    "print(result_at_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
